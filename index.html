<!DOCTYPE HTML>
<html lang="en">
  <!-- Header -->
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Meng Song</title>
    <meta name="author" content="Meng Song">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>
  <!-- Body -->
  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr style="padding:0px">
          <td style="padding:0px">
            <!-- Intro -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr style="padding:0px">
                  <td style="padding:2.5%;width:63%;vertical-align:middle">
                    <p class="name" style="text-align: center;">
                      Meng Song
                    </p>
                    <p style="text-align: justify;">
                      I completed my PhD at <a href="http://www.cs.ucsd.edu/">UC San Diego</a>, where I was advised <a href="https://cseweb.ucsd.edu/~mkchandraker/">Prof. Manmohan Chandraker</a>.
                      <br>
                      <br>
                      Prior to that, I obtained my Master's degree at <a href="http://www.ri.cmu.edu/">the Robotics Institute, Carnegie Mellon University</a>, working with <a href="http://www.cs.cmu.edu/~abhinavg/">Prof. Abhinav Gupta</a> and <a href="https://www.linkedin.com/in/daniel-huber-22b2631/">Dr. Daniel Huber</a>.
                    </p>
                    <p style="text-align:center">
                      <a href="mailto:mes050@ucsd.edu">Email</a> &nbsp;/&nbsp;
                      <a href="data/meng_resume.pdf">CV</a> &nbsp;/&nbsp;
                      <a href="https://scholar.google.com/citations?user=UxuTHlcAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                      <a href="https://twitter.com/meng_song">Twitter</a> &nbsp;/&nbsp;
                      <a href="https://github.com/mengsong16">Github</a> &nbsp;/&nbsp;
                      <a href="https://www.linkedin.com/in/mengsong16">LinkedIn</a>
                    </p>
                  </td>
                  <td style="padding:2.5%;width:37%;max-width:37%">
                    <a href="images/photo_cropped.jpg"><img style="width:75%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/photo_cropped.jpg" class="hoverZoomLink"></a>
                  </td>
                </tr>
              </tbody>
            </table>
            <!-- Research interests -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p style="text-align: justify;">
                    My research is motivated by the goal of developing a mathematical construct of the intelligent agent from first principles. My recent work has primarily focused on answering the question "What is a good representation of states and goals in decision-making problems?" I explored this problem under three different learning paradigms: reinforcement learning, imitation learning, and unsupervised learning.
                  </p>
                </td>
              </tr>
              </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <!-- Publications -->
        <!-- RL generalize -->
        <tr>
          <td style="padding:16px;width:20%;vertical-align:middle">
            <div class="one">
              <img src='images/rl_generalize.png' width=100%>
            </div>
          </td>
          <td style="padding:8px;width:80%;vertical-align:middle">
            <span class="papertitle">Good Actions Succeed, Bad Actions Generalize: A Case Study on Why RL Generalizes Better</span>
            <br>
            <strong>Meng Song</strong>
            <br>
            <em>Preprint</em>, 2025
            <br>
            <a href="https://arxiv.org/abs/2503.15693">arXiv</a>
            /
            <a href="https://github.com/mengsong16/enlighten">code</a>
            <p></p>
            <p style="text-align: justify;">
            PPO and BC generalize differently in visual navigation: BC imitates successful trajectories, while PPO combinatorially stitches together past experiences, including failures, to solve new tasks and achieve stronger generalization.
            </p>
          </td>
        </tr> 
        <!-- Thesis -->
        <tr>
          <td style="padding:16px;width:20%;vertical-align:middle">
            <div class="one">
              <img src='images/phd_thesis.png' width=100%>
            </div>
          </td>
          <td style="padding:8px;width:80%;vertical-align:middle">
            <span class="papertitle">Towards Unsupervised Goal Discovery: Learning Plannable Representations with Probabilis-
tic World Modeling</span>
            <br>
            <strong>Meng Song</strong>
            <br>
            <em>PhD Thesis</em>, 2024
            <br>
            <a href="https://escholarship.org/content/qt33g971rx/qt33g971rx_noSplash_f96408a792fe0a65a6af9d5d97370eb7.pdf">escholarship</a>
            <p></p>
            <p style="text-align: justify;">
              Learning through interaction is a foundational principle in both human and animal learning. 
              In a broad sense, intelligent agents can be formulated as goal-directed systems
              interacting with an uncertain environment. 
              <br>
              <br>
              Despite the generality of this definition, a key challenge in computationally grounding it lies in how to effectively set up and represent goals
              and purposes. This dissertation explores this question through the lens of various machine
              learning paradigms.
            </p>
          </td>
        </tr> 
        <!-- Subgoal -->
        <tr>
          <td style="padding:16px;width:20%;vertical-align:middle">
            <div class="one">
              <img src='images/subgoal.png' width=100%>
            </div>
          </td>
          <td style="padding:8px;width:80%;vertical-align:middle">
            <span class="papertitle">Towards Unsupervised Goal Discovery: Learning Plannable Representations with Probabilis-
tic World Modeling</span>
            <br>
            <strong>Meng Song</strong>
            <br>
            <em>Geometry-grounded Representation Learning and Generative Modeling Workshop at International Conference on Machine Learning (ICML)</em>, &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
            <br>
            <a href="https://arxiv.org/abs/2403.10875">arXiv</a>
            <p></p>
            <p style="text-align: justify;">
              A novel probabilistic world model trained with contrastive learning. The learned latent space enables subgoal discovery, asymmetric transition modeling, and supports highly efficient planning without requiring any inference-time search.  
            </p>
          </td>
        </tr> 
        <!-- Minimalist Prompt -->
        <tr>
          <td style="padding:16px;width:20%;vertical-align:middle">
            <div class="one">
              <img src='images/minimal_prompt.png' width=100%>
            </div>
          </td>
          <td style="padding:8px;width:80%;vertical-align:middle">
            <span class="papertitle">A Minimalist Prompt for Zero-Shot Policy Learning</span>
            <br>
            <strong>Meng Song</strong>
            <a href="https://scholar.google.com/citations?user=ScLUQ-YAAAAJ&hl=en">Xuezhi Wang</a>,
            <a href="https://tanaybiradar.com/">Tanay Biradar</a>,
            <a href="https://yaoqin1.github.io/">Yao Qin</a>, 
            <a href="https://cseweb.ucsd.edu/~mkchandraker/">Manmohan Chandraker</a>
            <br>
            <em>Task Specification Workshop at The Robotics: Science and Systems (RSS)</em>, 2024
            <br>
            <a href="https://arxiv.org/pdf/2405.06063">arXiv</a>
            /
            <a href="https://github.com/mengsong16/prompt_dt">code</a>
            <p></p>
            <p style="text-align: justify;">
            A novel prompting method that enables interpretable zero-shot generalization in unseen robotics tasks without requiring demonstrations and surpasses few-shot baselines.
            </p>
          </td>
        </tr>
        <!-- RL prompt -->
        <tr>
          <td style="padding:16px;width:20%;vertical-align:middle">
            <div class="one">
              <img src='images/prompt_rl.png' width=100%>
            </div>
          </td>
          <td style="padding:8px;width:80%;vertical-align:middle">
            <span class="papertitle">RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning</span>
            <br>
            <a href="https://mingkaid.github.io/">Mingkai Deng</a>,
            <a href="https://scholar.google.com/citations?user=woyUwp0AAAAJ&hl=zh-CN">Jianyu Wang</a>,
            <a href="https://hsiehjackson.github.io/">Cheng-Ping Hsieh</a>, 
            <a href="https://www.linkedin.com/in/yhwang0315/">Yihan Wang</a>
            <a href="https://han-guo.info/">Han Guo</a>
            <a href="https://www.tshu.io/">Tianmin Shu</a>
            <strong>Meng Song</strong>
            <a href="https://www.cs.cmu.edu/~epxing/">Eric P. Xing</a>
            <a href="https://scholar.google.com/citations?user=N7_xhHoAAAAJ&hl=en">Zhiting Hu</a>
            <br>
            <em>Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2022
            <br>
            <a href="https://arxiv.org/abs/2205.12548">arXiv</a>
            /
            <a href="https://blog.ml.cmu.edu/2023/02/24/rlprompt-optimizing-discrete-text-prompts-with-reinforcement-learning/">blog</a>
            <p></p>
            <p style="text-align: justify;">
            RL-based prompt optimization approach outperforms a wide range of finetuning and prompting baselines on text classification and style transfer tasks.
            </p>
          </td>
        </tr>
      
      </tbody>
    </table>
    <!-- Miscellanea -->
    <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;">
      <tbody>
        <tr>
          <td>
            <h2>Miscellanea</h2>
          </td>
        </tr>
      </tbody>
    </table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td align="center" style="padding:16px;width:20%;vertical-align:middle">
              <div class="colored-box" style="background-color: #fcb97d;">
              <h2>Micropapers</h2>
              </div>
          </td>
          <td style="padding:8px;width:80%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
            <br>
            <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
            <br>
            <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
            <br>
            <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
          </td>
        </tr>

        <tr>
          <td align="center" style="padding:16px;width:20%;vertical-align:middle">
              <div class="colored-box" style="background-color: #aaba9e;">
              <h2>Recorded Talks</h2>
              </div>
          </td>
          <td style="padding:8px;width:80%;vertical-align:center">
            <a href="https://www.youtube.com/watch?v=hFlF33JZbA0">Radiance Fields and the Future of Generative Media, 2025</a><br>				  
            <a href="https://www.youtube.com/watch?v=h9vq_65eDas">View Dependent Podcast, 2024</a><br>
            <a href="https://www.youtube.com/watch?v=4tDhYsFuEqo">Bay Area Robotics Symposium, 2023
            </a><br>
            <a href="https://youtu.be/TvWkwDYtBP4?t=7604">EGSR Keynote, 2021</a><br>
            <a href="https://www.youtube.com/watch?v=nRyOzHpcr4Q">TUM AI Lecture Series, 2020</a><br>
            <a href="https://www.youtube.com/watch?v=HfJpQCBTqZs">Vision & Graphics Seminar at MIT, 2020</a>
          </td>
        </tr>

        <tr>
          <td align="center" style="padding:16px;width:20%;vertical-align:middle">
              <div class="colored-box" style="background-color: #c6b89e;">
              <h2>Academic Service</h2>
              </div>
          </td>
          <td style="padding:8px;width:80%;vertical-align:center">
            <a href="https://iccv.thecvf.com/">Lead Area Chair, ICCV 2025</a>
            <br>
            <a href="https://cvpr.thecvf.com/Conferences/2025/Organizers">Lead Area Chair, CVPR 2025</a>
            <br>
            <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
            <br>
            <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
            <br>
            <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
            <br>
            <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
            <br>
            <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
            <br>
            <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
          </td>
        </tr>
      
        <tr>
          <td align="center" style="padding:16px;width:20%;vertical-align:middle">
              <div class="colored-box" style="background-color: #edd892;">
              <h2>Teaching</h2>
              </div>
          </td>
          <td style="padding:8px;width:80%;vertical-align:center">
            <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
            <br>
            <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
            <br>
            <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
          </td>
        </tr>
      
      </tbody>
    </table>

    <!-- Acknowledgement -->
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="padding:0px">
            <br>
            <p style="text-align:right;font-size:small;">
              Template stolen from <a href="https://github.com/jonbarron/jonbarron.github.io">Jon Barron</a>.
            </p>
          </td>
        </tr>
      </tbody>
      </table>
      </td>
      </tr>
    </table>

  </body>
</html>
